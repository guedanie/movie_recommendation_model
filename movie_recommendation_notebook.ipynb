{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Science Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# py imports\n",
    "from acquire import prepare_data\n",
    "from prepare import prep_readme_data\n",
    "import model\n",
    "\n",
    "# NLP Imports\n",
    "import nltk\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk.sentiment\n",
    "\n",
    "# Clustering Imports\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation Tool\n",
    "\n",
    "Have you ever finished a movie, and were so in entranced by the concept that you wanted to see more movies like it? Or have you ever gone into a streaming service looking for a specific movie, but can't find it? \n",
    "\n",
    "Recommendation models are very common now a days, and are integral in many different type of industries, ranging from Amazon product recommendations, HEB groceries. Recommendation models can also be built in many different ways, and it often depend on how the data is strucutred. \n",
    "\n",
    "In this case, I will be using a more classical approach, and use NLP and clustering techniques to create my own movie recommendation tool. The idea is that users will be able to input a movie title, and then a list of similar movies will be outputed by the tool, along with some relevant information. \n",
    "\n",
    "## Background\n",
    "\n",
    "Using a data set found on Kaggle, I will be looking at movies published in the US for the past 20+ years, and using NLP strategies to:\n",
    "\n",
    "1. Explore the data, and see if any interesting patterns arise\n",
    "2. Create a clustering modeling that can help us identify movies that are similar to each other based on:\n",
    "    1. Genre\n",
    "    1. Description\n",
    "    1. Avg score by viewers\n",
    "    1. Director\n",
    "    1. Actors\n",
    "    \n",
    "The data can be found [here](https://www.kaggle.com/stefanoleone992/imdb-extensive-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title = pd.read_csv(\"IMDb movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What is are biggest markets in terms of movie production? \n",
    "\n",
    "movie_title.groupby(\"country\").title.count().sort_values(ascending=False).nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What year did most movies get published?\n",
    "\n",
    "movie_title.groupby(\"date_published\").title.count().nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What data range do we have? \n",
    "\n",
    "movie_title.date_published.min(), movie_title.date_published.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDITIONAL_STOPWORDS = ['r', 'u', '2', 'ltgt']\n",
    "\n",
    "# def clean(text: str) -> list:\n",
    "#     'A simple function to cleanup text data'\n",
    "#     wnl = nltk.stem.WordNetLemmatizer()\n",
    "#     stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n",
    "#     text = (text.encode('ascii', 'ignore')\n",
    "#              .decode('utf-8', 'ignore')\n",
    "#              .lower())\n",
    "#     words = re.sub(r'[^\\w\\s]', '', text).split() # tokenization\n",
    "#     return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this project, we will only look to use movies from the US. If the opportunity to scale up the project is possible, then we will add additional countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = movie_title[(movie_title.country == \"USA\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that we have a couple of missing values.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps for Removing Null Values**:\n",
    "\n",
    "1. The movie description will be a large part indicator or similarity, and as such, I want movies that have a description. I will drop any null values in this column\n",
    "1. I will explore that language column, as I suspect at this moment that these shoud be all inglish\n",
    "1. Similarly to the description, the director would play a big influence and as such I am thinking of dropping all null values from this column\n",
    "1. While the meta score value would be really useful - there are too many missing values, and as such I will drop this column. Same for the `reviews_from_critics`\n",
    "1. Might be able to impude a value for the missing `reviews_from_users`\n",
    "1. I might be able to find the missing writers from the other IMBD file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given that hte majority of the movies are exclusively English, and we know that we are only looking at movies\n",
    "# made in the US, I can speculate that it is very likely these movies were at least partially made in english\n",
    "# As such, I will impode the missing values\n",
    "\n",
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language = df.language.fillna(\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nulls from director and description\n",
    "\n",
    "df = df[df.description.notnull()]\n",
    "\n",
    "df = df[df.director.notnull()]\n",
    "\n",
    "df = df[df.writer.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the avg budget for all movies so that we can use it to impude values?\n",
    "\n",
    "df.budget = df.budget.fillna(\"$ 0\")\n",
    "\n",
    "df = df[~df.budget.str.contains(\"ESP\")]\n",
    "\n",
    "df = df[~df.budget.str.contains(\"GBP\")]\n",
    "\n",
    "df = df[~df.budget.str.contains(\"CAD\")]\n",
    "\n",
    "df = df[~df.budget.str.contains(\"PYG\")]\n",
    "\n",
    "df = df[~df.budget.str.contains(\"AUD\")]\n",
    "\n",
    "df = df[~df.budget.str.contains(\"EUR\")]\n",
    "\n",
    "df = df[~df.budget.str.contains(\"RUR\")]\n",
    "\n",
    "avg_budget = df.budget.str.replace(\"$\", '').astype(int).mean()\n",
    "\n",
    "df.budget = df.budget.str.replace(\"$\", '').astype(int)\n",
    "\n",
    "df.budget = df.budget.replace(0, avg_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will do something similar for US gross income\n",
    "\n",
    "median_income = df[(df.usa_gross_income.notnull()) & (df.usa_gross_income.str.contains(\"$\", regex=False))].usa_gross_income.str.replace(\"$\", '').astype(int).median()\n",
    "\n",
    "df.usa_gross_income = df.usa_gross_income.fillna(\"$ 0\")\n",
    "\n",
    "df.usa_gross_income = (\n",
    "    df[df.usa_gross_income.str.contains(\"$\", regex=False)]\n",
    "    .usa_gross_income.str.replace(\"$\", '')\n",
    "    .astype(int)\n",
    "    .replace(0, median_income)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with too many null values\n",
    "\n",
    "df = df.drop(columns=[\"worlwide_gross_income\", \"metascore\", \"reviews_from_users\", \"reviews_from_critics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any remaining null values\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now we have no null values, and still have over 26000 movie titles\n",
    "\n",
    "df.isnull().sum(), df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a template for Seaborn and Matplot\n",
    "plt.rc('figure', figsize=(13, 7))\n",
    "plt.rc('font', size=14)\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = prep_readme_data(df, \"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# What are the most common words in movie descriptions?\n",
    "\n",
    "all_words = model.clean(' '.join(df.description))\n",
    "\n",
    "pd.Series(all_words).value_counts().head(15).plot.barh()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common words by genre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What are the top most common genres?\n",
    "\n",
    "df.genre.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create new lemmatize groups for the top five categories\n",
    "\n",
    "drama = model.clean(' '.join(df[df.genre == \"Drama\"].description))\n",
    "comedy = model.clean(' '.join(df[df.genre == \"Comedy\"].description))\n",
    "comedy_drama = model.clean(' '.join(df[df.genre == \"Comedy, Drama\"].description))\n",
    "horror = model.clean(' '.join(df[df.genre == \"Horror\"].description))\n",
    "drame_romance = model.clean(' '.join(df[df.genre == \"Drama, Romance\"].description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Are the most common words in the most popular genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(2,3,1)\n",
    "pd.Series(drama).value_counts().head(3).plot.barh()\n",
    "plt.title(\"Drama\")\n",
    "plt.subplot(2,3,2)\n",
    "pd.Series(comedy).value_counts().head(3).plot.barh()\n",
    "plt.title(\"Comedy\")\n",
    "plt.subplot(2,3,3)\n",
    "pd.Series(comedy_drama).value_counts().head(3).plot.barh()\n",
    "plt.title(\"Comedy Drama\")\n",
    "plt.subplot(2,3,4)\n",
    "pd.Series(horror).value_counts().head(3).plot.barh()\n",
    "plt.title(\"Horror\")\n",
    "plt.subplot(2,3,5)\n",
    "pd.Series(drame_romance).value_counts().head(3).plot.barh()\n",
    "plt.title(\"Drama Romance\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common words throughout time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date_published = pd.to_datetime(df.date_published)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_bigrams = df.set_index('date_published').resample('Y').description.agg([model.most_frequent_bigram, \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_bigrams[\"most_frequent_bigram\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 9))\n",
    "most_common_bigrams.plot(ax=ax)\n",
    "plt.title(\"What are the most common bigrams over time?\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Date Movie was Published\")\n",
    "for i in range(1, most_common_bigrams.shape[0]):\n",
    "    if most_common_bigrams[\"most_frequent_bigram\"][i] != most_common_bigrams[\"most_frequent_bigram\"][i-1]:\n",
    "        ax.text(f\"{most_common_bigrams.index[i]}\", most_common_bigrams[\"count\"][i] + 20,  f\"{most_common_bigrams.most_frequent_bigram[i]}\", rotation = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common bigrams in high voted movies vs low?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_bigrams = df.groupby(\"avg_vote\").description.agg([model.most_frequent_bigram, \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 9))\n",
    "most_common_bigrams.plot(ax=ax)\n",
    "plt.title(\"What are the most common bigrams based on the movie score?\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Avg score given by viewers\")\n",
    "for i in range(1, most_common_bigrams.shape[0]):\n",
    "    if most_common_bigrams[\"most_frequent_bigram\"].iloc[i] != most_common_bigrams[\"most_frequent_bigram\"].iloc[i-1]:\n",
    "        if most_common_bigrams.index[i] < 7:\n",
    "            ax.text(most_common_bigrams.index[i], most_common_bigrams[\"count\"].iloc[i],  f\"{most_common_bigrams.most_frequent_bigram.iloc[i]}\", rotation = -45)\n",
    "        else:\n",
    "            ax.text(most_common_bigrams.index[i], most_common_bigrams[\"count\"].iloc[i],  f\"{most_common_bigrams.most_frequent_bigram.iloc[i]}\", rotation = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common words in high grossing movies vs low?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"usa_gross_bin\"] = pd.cut(df.usa_gross_income, 10, labels=[1,2,3,4,5,6,7,8,9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_bigrams = df.groupby(\"usa_gross_bin\").description.agg([model.most_frequent_bigram, \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"usa_gross_bin\"] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 9))\n",
    "most_common_bigrams.plot(ax=ax)\n",
    "plt.title(\"What are the most common bigrams over based on the movie's gross income?\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"USA Gross Income, in Millions\")\n",
    "for i in most_common_bigrams.index:\n",
    "    ax.text(i-1, most_common_bigrams[\"count\"][i],  f\"{most_common_bigrams.most_frequent_bigram[i]}\", rotation = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are highest grossing directors of all times?\n",
    "\n",
    "\n",
    "df.groupby(\"director\").usa_gross_income.sum().sort_values(ascending=False).head(5).plot.barh()\n",
    "plt.title(\"What are the top grossing directors?\")\n",
    "plt.xlabel(\"Dollars\")\n",
    "plt.ylabel(\"Director\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the top genres by genre?\n",
    "\n",
    "df.groupby(\"genre\").usa_gross_income.sum().sort_values(ascending=False).head(5).plot.barh()\n",
    "plt.title(\"What is the highest grossing genre?\")\n",
    "plt.xlabel(\"Dollars\")\n",
    "plt.ylabel(\"Genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.genre == \"Animation, Drama, Sci-Fi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the highest voted directors?\n",
    "\n",
    "df.groupby(\"director\").avg_vote.mean().sort_values(ascending=False).head(5).plot.barh()\n",
    "plt.title(\"Which are the highest voted directors, on average?\")\n",
    "plt.xlabel(\"Avg votes\")\n",
    "plt.ylabel(\"Director\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the highest voted genres?\n",
    "\n",
    "df.groupby(\"genre\").avg_vote.mean().sort_values(ascending=False).head(5).plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "Can sentiment analysis of the movie description help us identify if they are similar movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = nltk.sentiment.SentimentIntensityAnalyzer()\n",
    "df[\"sentiment\"] = df.clean_lemmatized.apply(lambda blog: sia.polarity_scores(blog)[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.groupby(\"genre\").sentiment.mean().sort_values(ascending=False).head(5).plot.barh()\n",
    "plt.title(\"What are the 5 most positive genres?\")\n",
    "plt.xlabel(\"Sentiment Score\")\n",
    "plt.ylabel(\"Genre Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"genre\").sentiment.mean().sort_values().head(5).plot.barh()\n",
    "plt.title(\"What are the 5 most negative genres?\")\n",
    "plt.xlabel(\"Sentiment Score\")\n",
    "plt.ylabel(\"Genre Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the most positive movie description?\n",
    "\n",
    "df.nlargest(1, \"sentiment\").description.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the most negative movie description?\n",
    "\n",
    "df.nsmallest(1, \"sentiment\").description.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that overall, animation movies tend to have more positive descriptions. This makes sense, as most animation movies tend to target a younger audience, or a family audience. It should be noted that we are using a sentiment analysis that was largely developed for social media analysis, and as such, it was trained on a a very different corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further questions\n",
    "\n",
    "1. Does the publish month make a difference in gross_income?\n",
    "1. Does the publish month make a difference in avg_vote?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "For modeling, we will most likely need to do a bag of words, and then use those features are a metric for clustering\n",
    "\n",
    "The simple recommendation model:\n",
    "\n",
    "* We will look to do a traditional clustering, by looking at features that are already numerical. These features will be:\n",
    "    * Year release\n",
    "    * Run time\n",
    "    * Avg vote\n",
    "    * Do a `One Hot Encoder` for genre\n",
    "  \n",
    "A more advance model would look to use NLP practices to actually model based on the description, on top of some of the other features previously mentioned.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Filter data based on the genre\n",
    "2. Cluster the data based on `avg_votes`, `usa_gross_income`, `year` and `duration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_readme_data(df, \"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df[[\"title\", \"avg_vote\", \"usa_gross_income\", \"year\", \"duration\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df_num.set_index(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = df_num, x= \"duration\", y= \"avg_vote\", hue=\"year\")\n",
    "plt.title(\"Is there a relationship between movie length and avg vote?\")\n",
    "plt.ylabel(\"Avg Votes\")\n",
    "plt.xlabel(\"Movie Duration, in minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we see that there is not a very distinct difference between movie length and avg score. It is insteresting, however, that newer movies (post-2000) seem to be, on average, a bit longer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = df_num, x= \"usa_gross_income\", y= \"avg_vote\", hue=\"year\")\n",
    "plt.title(\"Is there a relationship between gross income and avg vote?\")\n",
    "plt.ylabel(\"Avg Votes\")\n",
    "plt.xlabel(\"USA Gross Income, in dollars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also seems that there are not a lot of significant differences between gross income and movie score. This is probably largely influenced by the fact that we had to impude some of the missing income, resulting in some similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to scale the data\n",
    "minmax = MinMaxScaler()\n",
    "scaled_df = minmax.fit_transform(df_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of KMeans \n",
    "kmeans = KMeans(n_clusters=5, random_state=123)\n",
    "# Use fit_predict to cluster the dataset\n",
    "predictions = kmeans.fit_predict(scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster\"] = \"cluster_\" + df.cluster.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "#### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we test\n",
    "\n",
    "test = \"Toy Story\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.simple_movie_recommender(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "#### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Bridesmaids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.simple_movie_recommender(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"A Quiet Place\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.simple_movie_recommender(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our function works relatively well. The way the function works is that it looks in the database for the genre and cluster that the `test` title has. It then filters that data using these masks, and returns the top 25 matches of titles that have a similar genre, and at the same time had a similar run-time, release year, avg votes and year (based on the cluster). \n",
    "\n",
    "The tool works fairly well, but ceirtainly requires further testing. Some of the abilities I want to implement:\n",
    "\n",
    "1. If a movie title is duplicated (i.e \"Parent Trap\"), then it would assume that it is the most recent title. \n",
    "1. At the moment, the tool only looks at the first genre. For example, if a movie is categorized as \"Action, Adventure, Comedy\", the matches are based on containing only \"Action\". By implementing a series of conditionals, it might be possible to further improve the model's accuracy.\n",
    "\n",
    "In order to improve the accuracy of the model, I am hoping we can use more advanced NLP techniques to actually group recommendations based on the movie descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Model with TF-IDF\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Filter data based on genre\n",
    "1. Cluster the data based on the TFIDF of the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_readme_data(df, \"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model.simple_cluster(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"combined_data\"] = df.genre + \" \" + df.director + \" \" + df.clean_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(df.clean_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of KMeans to find seven clusters\n",
    "kmeans = KMeans(n_clusters=5, random_state =123)\n",
    "# Use fit_predict to cluster the dataset\n",
    "predictions = kmeans.fit_predict(tfidfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster_description\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster_description\"] = \"cluster_\" + df.cluster_description.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "#### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Toy Story\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.complex_movie_recommendation(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "**Test 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Bridesmaids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.complex_movie_recommendation(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "**Test 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"A Quiet Place\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.complex_movie_recommendation(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logic behind the code is working as I expect it - however, there needs to be further testing with the size of the clusters to better arrive at an optimal recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Model with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_readme_data(df, \"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model.simple_cluster(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"combined_data\"] = df.genre + \" \" + df.director + \" \" + df.clean_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "cv = cv.fit_transform(df.clean_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of KMeans to find seven clusters\n",
    "kmeans = KMeans(n_clusters=5, random_state = 123)\n",
    "# Use fit_predict to cluster the dataset\n",
    "predictions = kmeans.fit_predict(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster_description\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster_description\"] = \"cluster_\" + df.cluster_description.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "#### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Toy Story\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.complex_movie_recommendation(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the other `Toy Story` movies are recommended. This means that the actual count vectorizer is not being as effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "**Test 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Bridesmaids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.complex_movie_recommendation(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This models struggles the most with the Romantic Comedies, as it returns the smallest list of recommendations, and after some research, there are other movies that I would prefer are recommended over this one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "**Test 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"A Quiet Place\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.complex_movie_recommendation(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Model with Bag of Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_readme_data(df, \"description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model.simple_cluster(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"combined_data\"] = df.genre + \" \" + df.director + \" \" + df.clean_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cv.fit_transform(df.clean_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of KMeans to find seven clusters\n",
    "kmeans = KMeans(n_clusters=5, random_state=123)\n",
    "# Use fit_predict to cluster the dataset\n",
    "predictions = kmeans.fit_predict(cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster_description\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cluster_description\"] = \"cluster_\" + df.cluster_description.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "#### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Toy Story\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.complex_movie_recommendation(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, this is the first model that recommends all three other `Toy Story` movies. All previous models would recommend one or two of the sequels, but never all three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "**Test 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"Bridesmaids\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.complex_movie_recommendation(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "**Test 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"A Quiet Place\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.complex_movie_recommendation(df, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We have 4 working movie recommendation models. Given the nature of this project, there is no way we can actually test for accuracy, given that we are using unsupervised machine learning. \n",
    "\n",
    "After some preliminary testing, I found that the bag of ngrams complex model is likely the best of the four models. The reason for this is because it was the only one that recommended all other `Toy Story` movies. It also had the most similar recommendations for `A Quiet Place`, which was the test that the other models struggle with the most. Unfortunately, I don't think this model performs as well as the simple model when it comes to `Bridesmaides`. The simple model's recommendations for this particular title are slightly better, as they seem more relevant, and there seems to be more uniformity about the movie release year. That being said, this is genre where I have the least amount of experience, and so it is harder to judge the model's effectiveness. \n",
    "\n",
    "This will likely be the end of the project, as further testing and tweaking would require users that would be willing to use the tool, and give their own input on the model's selection. \n",
    "\n",
    "I will create a command line app that will serve as a prototype, but the objective of the project was to review NLP and clustering basics, while exploring an IMBd database, and in that sense, the project was a success. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
