{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import nltk.sentiment\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(13, 7))\n",
    "plt.rc('font', size=14)\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title = pd.read_csv(\"IMDb movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "USA       27490\n",
       "India      5540\n",
       "UK         3869\n",
       "France     2975\n",
       "Japan      2850\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is are biggest markets in terms of movie production? \n",
    "\n",
    "movie_title.groupby(\"country\").title.count().sort_values(ascending=False).nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_published\n",
       "2010    111\n",
       "1999    105\n",
       "2008    101\n",
       "1997     92\n",
       "1985     90\n",
       "1996     89\n",
       "2009     89\n",
       "1989     85\n",
       "2011     85\n",
       "1987     84\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What year did most movies get published?\n",
    "\n",
    "movie_title.groupby(\"date_published\").title.count().nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1906-12-26', '2020-05-22')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What data range do we have? \n",
    "\n",
    "movie_title.date_published.min(), movie_title.date_published.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDITIONAL_STOPWORDS = ['r', 'u', '2', 'ltgt']\n",
    "\n",
    "def clean(text: str) -> list:\n",
    "    'A simple function to cleanup text data'\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n",
    "    text = (text.encode('ascii', 'ignore')\n",
    "             .decode('utf-8', 'ignore')\n",
    "             .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split() # tokenization\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this project, we will only look to use movies from the US. If the opportunity to scale up the project is possible, then we will add additional countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = movie_title[(movie_title.country == \"USA\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imdb_title_id                0\n",
       "title                        0\n",
       "original_title               0\n",
       "year                         0\n",
       "date_published               0\n",
       "genre                        0\n",
       "duration                     0\n",
       "country                      0\n",
       "language                   307\n",
       "director                    28\n",
       "writer                     191\n",
       "production_company        1139\n",
       "actors                      22\n",
       "description                 76\n",
       "avg_vote                     0\n",
       "votes                        0\n",
       "budget                   17213\n",
       "usa_gross_income         19940\n",
       "worlwide_gross_income    19710\n",
       "metascore                21145\n",
       "reviews_from_users         279\n",
       "reviews_from_critics      1728\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we see that we have a couple of missing values.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps for Removing Null Values**:\n",
    "\n",
    "1. The movie description will be a large part indicator or similarity, and as such, I want movies that have a description. I will drop any null values in this column\n",
    "1. I will explore that language column, as I suspect at this moment that these shoud be all inglish\n",
    "1. Similarly to the description, the director would play a big influence and as such I am thinking of dropping all null values from this column\n",
    "1. While the meta score value would be really useful - there are too many missing values, and as such I will drop this column. Same for the `reviews_from_critics`\n",
    "1. Might be able to impude a value for the missing `reviews_from_users`\n",
    "1. I might be able to find the missing writers from the other IMBD file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English                                              23976\n",
       "English, Spanish                                       695\n",
       "English, French                                        440\n",
       "English, German                                        198\n",
       "English, Italian                                       195\n",
       "                                                     ...  \n",
       "English, Japanese, Yiddish, German                       1\n",
       "English, Greek, Japanese                                 1\n",
       "English, French, Latin, Scottish Gaelic, Italian         1\n",
       "English, French, Turkish, Hebrew, Arabic, Spanish        1\n",
       "English, French, German, Arabic                          1\n",
       "Name: language, Length: 629, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given that hte majority of the movies are exclusively English, and we know that we are only looking at movies\n",
    "# made in the US, I can speculate that it is very likely these movies were at least partially made in english\n",
    "# As such, I will impode the missing values\n",
    "\n",
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language = df.language.fillna(\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nulls from director and description\n",
    "\n",
    "df = df[df.description.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.director.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.writer.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the avg budget for all movies so that we can use it to impude values?\n",
    "\n",
    "df.budget = df.budget.fillna(\"$ 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.budget.str.contains(\"ESP\")]\n",
    "\n",
    "df = df[~df.budget.str.contains(\"GBP\")]\n",
    "\n",
    "df = df[~df.budget.str.contains(\"CAD\")]\n",
    "\n",
    "df = df[~df.budget.str.contains(\"PYG\")]\n",
    "\n",
    "df = df[~df.budget.str.contains(\"AUD\")]\n",
    "\n",
    "df = df[~df.budget.str.contains(\"EUR\")]\n",
    "\n",
    "df = df[~df.budget.str.contains(\"RUR\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_budget = df.budget.str.replace(\"$\", '').astype(int).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.budget = df.budget.str.replace(\"$\", '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.budget = df.budget.replace(0, avg_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will do something similar for US gross income\n",
    "\n",
    "median_income = df[(df.usa_gross_income.notnull()) & (df.usa_gross_income.str.contains(\"$\", regex=False))].usa_gross_income.str.replace(\"$\", '').astype(int).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.usa_gross_income = df.usa_gross_income.fillna(\"$ 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.usa_gross_income = (\n",
    "    df[df.usa_gross_income.str.contains(\"$\", regex=False)]\n",
    "    .usa_gross_income.str.replace(\"$\", '')\n",
    "    .astype(int)\n",
    "    .replace(0, median_income)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with too many null values\n",
    "\n",
    "df = df.drop(columns=[\"worlwide_gross_income\", \"metascore\", \"reviews_from_users\", \"reviews_from_critics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any remaining null values\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(imdb_title_id         0\n",
       " title                 0\n",
       " original_title        0\n",
       " year                  0\n",
       " date_published        0\n",
       " genre                 0\n",
       " duration              0\n",
       " country               0\n",
       " language              0\n",
       " director              0\n",
       " writer                0\n",
       " production_company    0\n",
       " actors                0\n",
       " description           0\n",
       " avg_vote              0\n",
       " votes                 0\n",
       " budget                0\n",
       " usa_gross_income      0\n",
       " dtype: int64, (26102, 18))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we have no null values, and still have over 26000 movie titles\n",
    "\n",
    "df.isnull().sum(), df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            fabled\n",
       "1             queen\n",
       "2             egypt\n",
       "3            affair\n",
       "4             roman\n",
       "            ...    \n",
       "402948       narrow\n",
       "402949         path\n",
       "402950      distant\n",
       "402951    celestial\n",
       "402952         city\n",
       "Length: 402953, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(clean(' '.join(df.description)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
